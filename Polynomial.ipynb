{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Polynomial Linear Regression</h1>\n",
    "<h2>Here we are using a \"Relative CPU Performance DataSet\"\n",
    "<a href = \"https://archive.ics.uci.edu/ml/datasets/Computer+Hardware\">Link</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('machine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adviser</th>\n",
       "      <th>32/60</th>\n",
       "      <th>125</th>\n",
       "      <th>256</th>\n",
       "      <th>6000</th>\n",
       "      <th>256.1</th>\n",
       "      <th>16</th>\n",
       "      <th>128</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7a</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7b</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7c</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/b</td>\n",
       "      <td>26</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>318</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adviser    32/60  125   256   6000  256.1  16  128  198  199\n",
       "0  amdahl   470v/7   29  8000  32000     32   8   32  269  253\n",
       "1  amdahl  470v/7a   29  8000  32000     32   8   32  220  253\n",
       "2  amdahl  470v/7b   29  8000  32000     32   8   32  172  253\n",
       "3  amdahl  470v/7c   29  8000  16000     32   8   16  132  132\n",
       "4  amdahl   470v/b   26  8000  32000     64   8   32  318  290"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,[0,2,3,4,5,6,7,8]].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['amdahl', 29, 8000, ..., 8, 32, 269],\n",
       "       ['amdahl', 29, 8000, ..., 8, 32, 220],\n",
       "       ['amdahl', 29, 8000, ..., 8, 32, 172],\n",
       "       ...,\n",
       "       ['sratus', 125, 2000, ..., 2, 14, 52],\n",
       "       ['wang', 480, 512, ..., 0, 0, 67],\n",
       "       ['wang', 480, 1000, ..., 0, 0, 45]], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>\n",
    "<h3>Dummy Encoding the first attribute</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "X[:,0] = labelencoder.fit_transform(X[:,0])\n",
    "onehotencoder = OneHotEncoder(categorical_features= [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   0., ...,   8.,  32., 269.],\n",
       "       [  1.,   0.,   0., ...,   8.,  32., 220.],\n",
       "       [  1.,   0.,   0., ...,   8.,  32., 172.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   2.,  14.,  52.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,  67.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,  45.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting into training set and test set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying Regression Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_regrs = LinearRegression()\n",
    "lin_regrs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_regrs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 82.69981422,  14.70398836,  29.58137242, 103.84705501,\n",
       "        33.93268772,  72.70709426, 118.05285602,   6.28797553,\n",
       "        23.94877436,  66.71995766,  19.02358401, 307.95921198,\n",
       "        31.73295684,  30.74646185,   6.75535245,  89.26569335,\n",
       "        65.31569262,  24.9484754 ,  52.79752917,  66.55664408,\n",
       "       377.81722564, -14.16777238,  55.46513876, 412.59331998,\n",
       "       197.17722089,  35.69875754,  38.1380225 , 124.28573592,\n",
       "        15.48014294,  29.04503994,  34.88952011,  16.42544843,\n",
       "        -3.63133705,   5.65224075,  51.29014187, 136.79968842,\n",
       "        14.39109178,  34.390149  , 188.36101616,  36.48452479,\n",
       "        54.92361175,  75.10882589,  37.90149004,  22.46717596,\n",
       "        99.82903453, 187.69855662,  32.04356626,  14.60560992,\n",
       "        22.35287835,  44.58899037,  14.02223964,  29.62568487])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74,  28,  35, 116,  28,  67,  72,  22,  46,  80,  25, 253,  20,\n",
       "        26,  22,  88,  75,  24,  34,  47, 382,  19,  52, 381, 181,  33,\n",
       "        33, 120,  25,  24,  30,  20,  15,  21,  48, 117,  29,  34, 175,\n",
       "        65,  18,  62,  34,  42,  81, 136,  53,  28,  23,  28,  27,  36])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can see the <b>Linear Regression</b> model isn't the best fit, so now we'll apply,</p>\n",
    "<h3>Polynomial Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_regrs = LinearRegression()\n",
    "poly_regrs.fit(X_poly,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly = poly_regrs.predict(poly.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  75.30997408,   30.03104043,   35.92920039,  111.78110774,\n",
       "         56.44875718,   68.78448468,   67.59046548,   22.45903038,\n",
       "         46.82883614,   82.42486623,   25.9435421 ,  256.78567415,\n",
       "         20.37970985,   47.23642168,   20.84466288,   88.95695915,\n",
       "         62.03780306,   24.60887296,   34.17691853,   62.11449081,\n",
       "        222.66091659,   20.45991548,   41.97071023,  309.01861875,\n",
       "        246.63039384,   34.6269452 ,  -77.50967663,  127.98925456,\n",
       "         27.98435858,   24.66207436,   19.73162579,   20.52095959,\n",
       "         16.50362063,   22.40371452,   41.72834644,  132.8512892 ,\n",
       "          2.30940188,   33.99989763, -147.76570084,   62.83660602,\n",
       "         10.23262476,   69.837918  ,   34.00051117,   44.95366763,\n",
       "         76.13707924,  157.3466641 ,   52.84695242,   39.00402934,\n",
       "         19.30427628,   27.35412545,   28.14752185,   32.83590601])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74,  28,  35, 116,  28,  67,  72,  22,  46,  80,  25, 253,  20,\n",
       "        26,  22,  88,  75,  24,  34,  47, 382,  19,  52, 381, 181,  33,\n",
       "        33, 120,  25,  24,  30,  20,  15,  21,  48, 117,  29,  34, 175,\n",
       "        65,  18,  62,  34,  42,  81, 136,  53,  28,  23,  28,  27,  36])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we can see, the <b>Polynomial regression</b> model yields better test outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
